version: '3.8'

services:
  llm:
    container_name: llm-worker
    image: llm-core:latest
    runtime: nvidia
    deploy:
      resources:
        limits:
          # cpus: 5
          memory: 100G
    build:
      context: ..
      dockerfile: Dockerfile
    env_file: .env
    environment:
      TOKENS_LEN: 16384
      GPU_MEMORY_UTILISATION: 0.9
      TENSOR_PARALLEL_SIZE: 2
      MODEL_PATH: /data/<your_path_to_model>
      NVIDIA_VISIBLE_DEVICES: <your_GPUs>
    volumes:
      - <your_path_to_data_in_docker>:/data
    ports:
      - "8677:8672"
    networks:
      - llm_wrap_network
    restart: unless-stopped

networks:
  llm_wrap_network:
    name: llm_wrap_network
    driver: bridge
